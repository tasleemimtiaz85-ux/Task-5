# Task-5
5th task of my Internship 
Navigation Menu
Internee.pk-DataAnalytics_Internship-Assignment5

 Â· 
last month
01_top_companies.png
Add files via upload
last month
02_mean_salary_by_title.png
Add files via upload
last month
03_salary_distribution.png
Add files via upload
last month
04_boxplot_salary_by_company.png
Add files via upload
last month
05_score_vs_salary.png
Add files via upload
last month
06_top_locations_pie.png
Add files via upload
last month
07_missingness_map.png
Add files via upload
last month
08_salary_unit_counts.png
Add files via upload
last month
Assignment Task-5.ipynb
Add files via upload
last month
Assignment Task_5.py
Add files via upload
last month
Data_Salaries.csv
Add files via upload
last month
Kaggle-DataSet_Link
Create Kaggle-DataSet_Link
last month
README.md
Update README.md
last month
Task 5.png
Add files via upload
last month
Repository files navigation
README
ğŸš€ Data Analytics Internship Task 5 | ğŸ§¹ Data Cleaning & Preprocessing â€” From Raw Data to Refined Intelligence
ğŸŒ Prelude: The Art of Turning Raw Data into Meaning
In the vast digital world, data is the new oil â€” but only when itâ€™s clean, structured, and ready to drive insight. ğŸ’¡ Through this project, I embarked on a data cleaning and preprocessing journey where raw and unstructured information was transformed into accurate, insightful, and analysis-ready datasets. This project focuses on mastering one of the most crucial stages in the data analytics lifecycle â€” ensuring data accuracy, consistency, and quality through systematic cleaning, transformation, and standardization. ğŸ§©âœ¨

ğŸ¯ Project Synopsis
The Data Cleaning & Preprocessing Project is an end-to-end initiative designed to prepare real-world data for analysis and visualization. Using Python (Pandas, NumPy, Matplotlib), this project demonstrates how data inconsistencies, missing values, and outliers are systematically handled to enhance data reliability and analytical depth. The dataset chosen for this project â€” Data_Salaries.csv â€” provides a fascinating view of job salaries, company scores, and professional attributes, serving as a perfect foundation for demonstrating preprocessing techniques in data analytics.

ğŸ“Š Dataset Overview: The Foundation of Accuracy
Dataset: Data_Salaries.csv Source: Kaggle â€” Real-world dataset capturing company names, job titles, locations, company scores, and salary details.

ğŸ§¾ Key Attributes:
ğŸ¢ Company â€” The organization offering a position
ğŸ’¼ Job Title â€” The role or designation held
ğŸ“ Location â€” The geographical location of the role
ğŸ’° Salary Estimate â€” Compensation figures (yearly/hourly)
â­ Company Score â€” Company performance or reputation rating
ğŸ’¡ Insight:
This dataset mirrors the real-world challenges analysts face â€” inconsistent text, missing values, messy salary formats, and outliers â€” making it an ideal playground to practice comprehensive data cleaning and preprocessing.

ğŸ§¹ Data Cleaning and Preprocessing Workflow
ğŸ”§ Step 1 â€” Data Inspection and Understanding

The dataset was first examined to understand its structure, column types, and missing values. Duplicates, nulls, and irrelevant fields were identified and summarized for systematic cleaning.

ğŸ§¼ Step 2 â€” Handling Missing Values
Missing or incomplete entries were treated carefully:

Filled company scores with median values.
Replaced missing locations with â€œNot Specified.
Removed or imputed incomplete salary records.
ğŸ“ Step 3 â€” Standardization and Formatting
To achieve consistency:

Salary fields were standardized (converted hourly/monthly values into annual estimates).
Text fields (company names, job titles, locations) were normalized â€” stripping spaces and capitalization issues.
Location fields were further split into City and State for finer analysis.
âš™ï¸ Step 4 â€” Outlier Detection and Treatment
Outliers in salary data were identified using Interquartile Range (IQR) and handled through winsorization, ensuring that extreme values didnâ€™t distort the overall insights.

ğŸ’¾ Step 5 â€” Clean Dataset Creation
After rigorous transformations, the cleaned dataset was saved as: cleaned_data_salaries.csv â€” a structured, reliable dataset ready for analysis and visualization.

ğŸ¨ Data Visualization & Insights
Visualization is where cleaned data becomes insightful. Using Matplotlib with a bright background and rich color palette, eight compelling visualizations were created to highlight salary trends, job distributions, and company performances:

ğŸ¢ Top 10 Companies by Job Listings â€” Bar chart of the most active employers.
ğŸ’¼ Mean Annual Salary by Job Title â€” Reveals which roles command higher compensation.
ğŸ’° Salary Distribution Histogram â€” Shows how salaries spread across roles.
ğŸ“¦ Salary Boxplot by Top Companies â€” Identifies variation and outliers.
â­ Company Score vs. Salary Scatter Plot â€” Displays the relationship between company reputation and pay.
ğŸ“ Top Hiring Locations (Pie Chart) â€” Shows where most opportunities are concentrated.
ğŸ§© Missing Values Heatmap â€” Highlights data completeness.
ğŸ§¾ Salary Unit Comparison â€” Analyzes distribution between hourly, yearly, and unspecified salaries.
ğŸ’¡ Insight:
Clean data enables meaningful visualization â€” patterns once hidden in noise now tell clear stories about pay scales, organizational behavior, and job market dynamics.

ğŸ§  Analytical Insights & Key Observations
ğŸŒŸ Core Findings:
Annual salary ranges exhibit strong clustering around mid-tier roles, with a few high-paying outliers.
Some companies consistently offer higher salaries aligned with strong company scores.
Certain job titles show high salary variance, hinting at skill-based compensation structures.
The datasetâ€™s original inconsistencies, once cleaned, revealed distinct trends across company types and regions.
ğŸ’¡ Inference:
Clean, standardized data is not just a preparatory step â€” itâ€™s the foundation of trustable analytics. Every insight depends on the accuracy achieved during preprocessing.

âš™ï¸ Tools and Technologies Used
ğŸ Programming Language: Python
ğŸ“¦ Libraries:
Pandas â€” For cleaning, transformation, and handling missing data
NumPy â€” For numerical and statistical operations
Matplotlib â€” For bright, visually engaging charts
ğŸ’¡ Workflow Integration:
The integration of these tools ensured a smooth transition from raw, inconsistent data to a refined, analytics-ready dataset with clear, actionable insights.

ğŸš€ Project Outcome: From Raw to Ready
This project demonstrates how effective preprocessing turns raw data into a structured foundation for analytics. By identifying inconsistencies, standardizing formats, and handling missing or extreme values, the dataset was transformed into an asset that drives reliable and visually rich insights.

ğŸŒŸ Reflections and Learnings
Cleaning data is not just a mechanical task â€” itâ€™s an art of discovery. It teaches patience, precision, and problem-solving. Every inconsistency tells a story about real-world data challenges, and every fix builds the credibility of analysis.

ğŸ’¬ Final Thought:
â€œGood analysis starts with clean data â€” because behind every chart, thereâ€™s a story that only clean data can tell.â€

ğŸ‘¨â€ğŸ’» Author
Tasleem Imtiaz 
Data Analytics Intern at Internee.pk
